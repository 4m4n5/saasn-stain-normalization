{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openslide as opsl\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import utils\n",
    "from arch import define_Gen, define_Dis\n",
    "import kornia\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage.transform\n",
    "import argparse\n",
    "from scipy.misc import imread, imresize\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "import openslide\n",
    "from openslide import OpenSlideError\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import pandas as pd\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "from skimage.morphology import binary_closing, binary_dilation, disk\n",
    "\n",
    "from sklearn.feature_extraction.image import reconstruct_from_patches_2d as reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optical_density(tile):\n",
    "    \"\"\"\n",
    "    Convert a tile to optical density values.\n",
    "    Args:\n",
    "    tile: A 3D NumPy array of shape (tile_size, tile_size, channels).\n",
    "    Returns:\n",
    "    A 3D NumPy array of shape (tile_size, tile_size, channels)\n",
    "    representing optical density values.\n",
    "    \"\"\"\n",
    "    tile = tile.astype(np.float64)\n",
    "    #od = -np.log10(tile/255 + 1e-8)\n",
    "    od = -np.log((tile+1)/240)\n",
    "    return od\n",
    "\n",
    "def keep_tile(tile_tuple, tile_size, tissue_threshold):\n",
    "    \"\"\"\n",
    "    Determine if a tile should be kept.\n",
    "    This filters out tiles based on size and a tissue percentage\n",
    "    threshold, using a custom algorithm. If a tile has height &\n",
    "    width equal to (tile_size, tile_size), and contains greater\n",
    "    than or equal to the given percentage, then it will be kept;\n",
    "    otherwise it will be filtered out.\n",
    "    Args:\n",
    "    tile_tuple: A (slide_num, tile) tuple, where slide_num is an\n",
    "      integer, and tile is a 3D NumPy array of shape\n",
    "      (tile_size, tile_size, channels).\n",
    "    tile_size: The width and height of a square tile to be generated.\n",
    "    tissue_threshold: Tissue percentage threshold.\n",
    "    Returns:\n",
    "    A Boolean indicating whether or not a tile should be kept for\n",
    "    future usage.\n",
    "    \"\"\"\n",
    "    slide_num, tile = tile_tuple\n",
    "    if tile.shape[0:2] == (tile_size, tile_size):\n",
    "        tile_orig = tile\n",
    "\n",
    "        # Check 1\n",
    "        # Convert 3D RGB image to 2D grayscale image, from\n",
    "        # 0 (dense tissue) to 1 (plain background).\n",
    "        tile = rgb2gray(tile)\n",
    "        # 8-bit depth complement, from 1 (dense tissue)\n",
    "        # to 0 (plain background).\n",
    "        tile = 1 - tile\n",
    "        # Canny edge detection with hysteresis thresholding.\n",
    "        # This returns a binary map of edges, with 1 equal to\n",
    "        # an edge. The idea is that tissue would be full of\n",
    "        # edges, while background would not.\n",
    "        tile = canny(tile)\n",
    "        # Binary closing, which is a dilation followed by\n",
    "        # an erosion. This removes small dark spots, which\n",
    "        # helps remove noise in the background.\n",
    "        tile = binary_closing(tile, disk(10))\n",
    "        # Binary dilation, which enlarges bright areas,\n",
    "        # and shrinks dark areas. This helps fill in holes\n",
    "        # within regions of tissue.\n",
    "        tile = binary_dilation(tile, disk(10))\n",
    "        # Fill remaining holes within regions of tissue.\n",
    "        tile = binary_fill_holes(tile)\n",
    "        # Calculate percentage of tissue coverage.\n",
    "        percentage = tile.mean()\n",
    "        check1 = percentage >= tissue_threshold\n",
    "\n",
    "        # Check 2\n",
    "        # Convert to optical density values\n",
    "        tile = optical_density(tile_orig)\n",
    "        # Threshold at beta\n",
    "        beta = 0.15\n",
    "        tile = np.min(tile, axis=2) >= beta\n",
    "        # Apply morphology for same reasons as above.\n",
    "        tile = binary_closing(tile, disk(2))\n",
    "        tile = binary_dilation(tile, disk(2))\n",
    "        tile = binary_fill_holes(tile)\n",
    "        percentage = tile.mean()\n",
    "        check2 = percentage >= tissue_threshold\n",
    "\n",
    "        return check1 and check2\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments(object):\n",
    "    def __init__(self, dictionary):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        for key in dictionary:\n",
    "            setattr(self, key, dictionary[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'epochs': 30,\n",
    "    'decay_epoch': 25,\n",
    "    'batch_size': 16,\n",
    "    'lr': 0.0002,\n",
    "    'load_height': 128,\n",
    "    'load_width': 128,\n",
    "    'gpu_ids': '0',\n",
    "    'crop_height': 128,\n",
    "    'crop_width': 128,\n",
    "    'alpha': 5, # Cyc loss\n",
    "    'beta': 5, # Scyc loss\n",
    "    'gamma': 2, # Dssim loss \n",
    "    'delta': 1, # Identity\n",
    "    'training': True,\n",
    "    'testing': True,\n",
    "    'results_dir': '/project/DSone/as3ek/data/ganstain/1000_SEEM_Cinn/results/',\n",
    "    'dataset_dir': '/project/DSone/as3ek/data/ganstain/1000_SEEM_Cinn/',\n",
    "    'checkpoint_dir': '/project/DSone/as3ek/data/ganstain/1000_SEEM_Cinn/checkpoint/',\n",
    "    'norm': 'batch',\n",
    "    'use_dropout': False,\n",
    "    'ngf': 64,\n",
    "    'ndf': 64,\n",
    "    'gen_net': 'unet_128',\n",
    "    'dis_net': 'n_layers',\n",
    "    'self_attn': True,\n",
    "    'spectral': True,\n",
    "    'log_freq': 50,\n",
    "    'custom_tag': '',\n",
    "    'gen_samples': True,\n",
    "    'specific_samples': False\n",
    "}\n",
    "\n",
    "args = Arguments(args)\n",
    "\n",
    "tag1 = 'noattn'\n",
    "if args.self_attn:\n",
    "    tag1 = 'attn'\n",
    "\n",
    "tag2 = 'nospec'\n",
    "if args.spectral:\n",
    "    tag2 = 'spectral'\n",
    "\n",
    "# Generate paths for checkpoint and results\n",
    "args.identifier = str(args.gen_net) + '_' + str(args.dis_net) + '_' \\\n",
    "+ str(args.lr) + '_' + args.norm + '_' + tag1 + '_' + tag2 + '_' + str(args.batch_size) + '_' \\\n",
    "+ str(args.load_height) + '_coefs_' + str(args.alpha) + '_' + str(args.beta) + '_' + str(args.gamma) + '_'\\\n",
    "+ str(args.delta) + '_' + args.custom_tag\n",
    "\n",
    "args.checkpoint_path = args.checkpoint_dir + args.identifier\n",
    "args.results_path = args.results_dir + args.identifier\n",
    "\n",
    "args.gpu_ids = []\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    args.gpu_ids.append(i)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "one_direction = True # If this is false. a -> b -> a will happen. Edit code for otherwise.\n",
    "gen_name = 'Gba' # Gba to generate b given a, i.e., a -> b\n",
    "PATH = '/project/DSone/as3ek/data/Cin_normal/'\n",
    "patch_size = 1000\n",
    "resize_to = 256\n",
    "target = '/scratch/as3ek/normalized_svs_filtered/'\n",
    "target_path_unnorm = '/project/DSone/as3ek/data/patches/1000/unnorm_cinn_tiff_patches/'\n",
    "target_path = '/project/DSone/as3ek/data/patches/1000/gannorm_seem_cinn/train/Normal/'\n",
    "thresh = 0.25\n",
    "save_WSI = True\n",
    "overlap = 0.5 # %-age area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network initialized with weights sampled from N(0,[0.02]).\n"
     ]
    }
   ],
   "source": [
    "if one_direction:\n",
    "    G = define_Gen(input_nc=3, output_nc=3, ngf=args.ngf, netG=args.gen_net, norm=args.norm, \n",
    "                                                    use_dropout= args.use_dropout, gpu_ids=args.gpu_ids, self_attn=args.self_attn, spectral = args.spectral)\n",
    "else:\n",
    "    Gab = define_Gen(input_nc=3, output_nc=3, ngf=args.ngf, netG=args.gen_net, norm=args.norm, \n",
    "                                                        use_dropout= args.use_dropout, gpu_ids=args.gpu_ids, self_attn=args.self_attn, spectral = args.spectral)\n",
    "    Gba = define_Gen(input_nc=3, output_nc=3, ngf=args.ngf, netG=args.gen_net, norm=args.norm, \n",
    "                                                    use_dropout= args.use_dropout, gpu_ids=args.gpu_ids, self_attn=args.self_attn, spectral = args.spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Loading checkpoint from /project/DSone/as3ek/data/ganstain/1000_SEEM_Cinn/checkpoint/unet_128_n_layers_0.0002_batch_attn_spectral_16_128_coefs_5_5_2_1_/latest.ckpt succeed!\n",
      "Eval mode\n"
     ]
    }
   ],
   "source": [
    "ckpt = utils.load_checkpoint('%s/latest.ckpt' % (args.checkpoint_path))\n",
    "if one_direction:\n",
    "    G.load_state_dict(ckpt[gen_name])\n",
    "    G.eval()\n",
    "else:\n",
    "    Gab.load_state_dict(ckpt['Gab'])\n",
    "    Gba.load_state_dict(ckpt['Gba'])\n",
    "    Gab.eval()\n",
    "    Gba.eval()\n",
    "print('Eval mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "num_files = len(os.listdir(PATH))\n",
    "\n",
    "for i, file in enumerate(os.listdir(PATH)):\n",
    "    image = opsl.OpenSlide(PATH + file)\n",
    "    rescale = resize_to / patch_size\n",
    "    new_dims = int(rescale * (image.dimensions[0] // 256) * 256) , int(rescale * (image.dimensions[1] // 256) * 256)\n",
    "    \n",
    "    # Initialize x and y coord\n",
    "    x_cord = 0\n",
    "    y_cord = 0\n",
    "    \n",
    "    if save_WSI:\n",
    "        joined_image = Image.new('RGB', (new_dims))\n",
    "    \n",
    "    while x_cord + patch_size < image.dimensions[0] - 1000:\n",
    "        while y_cord + patch_size < image.dimensions[1] - 1000:\n",
    "            patch = image.read_region((x_cord, y_cord), 0, (patch_size, patch_size))\n",
    "        \n",
    "            patch = patch.convert('RGB')\n",
    "            patch = imresize(patch, (resize_to, resize_to))\n",
    "            \n",
    "            # Check if we should keep patch\n",
    "            if keep_tile((0, patch), resize_to, thresh) == False:\n",
    "                y_cord = int(y_cord + (1 - overlap) * patch_size)\n",
    "                continue\n",
    "                \n",
    "            patch = patch.transpose(2, 0, 1)\n",
    "            patch = patch / 255.\n",
    "            patch = torch.FloatTensor(patch).to(device)\n",
    "            patch = transform(patch)\n",
    "            patch = patch.unsqueeze(0)\n",
    "            \n",
    "            # Save unnormalized patch\n",
    "            target_folder = target_path_unnorm\n",
    "            if not os.path.exists(target_folder):\n",
    "                os.mkdir(target_folder)\n",
    "            filename = target_folder + file.split('.')[0] + '__' + str(x_cord) + '_' + str(y_cord) + '.jpg'\n",
    "            torchvision.utils.save_image((patch + 1)/2, filename)\n",
    "            \n",
    "            if one_direction:\n",
    "                out = G(patch)\n",
    "            else:\n",
    "                out = Gba(patch)\n",
    "                out = Gab(out)\n",
    "            \n",
    "            # Save normalized patch\n",
    "            target_folder = target_path\n",
    "            if not os.path.exists(target_folder):\n",
    "                os.mkdir(target_folder)\n",
    "            filename = target_folder + file.split('.')[0] + '__' + str(x_cord) + '_' + str(y_cord) + '.jpg'\n",
    "            torchvision.utils.save_image((out + 1)/2, filename)\n",
    "            \n",
    "            if save_WSI:\n",
    "                out = (out + 1) / 2\n",
    "                # this converts it from GPU to CPU and selects first image\n",
    "                img = out.detach().cpu().numpy()[0]\n",
    "                #convert image back to Height,Width,Channels\n",
    "                img = np.transpose(img, (1,2,0))\n",
    "                patch_join = Image.fromarray(np.uint8(img*255))\n",
    "                joined_image.paste(patch_join, (int(x_cord*rescale), int(y_cord*rescale)))\n",
    "            \n",
    "            # Taking care of overlap\n",
    "            y_cord = int(y_cord + (1 - overlap) * patch_size)\n",
    "        \n",
    "        # Taking care of overlap\n",
    "        x_cord = int(x_cord + (1 - overlap) * patch_size)\n",
    "        y_cord = 0\n",
    "    \n",
    "    print(str(i + 1) + '/' + str(num_files) + ' Complete!')\n",
    "    if save_WSI:\n",
    "        if not os.path.exists(target):\n",
    "            os.makedirs(target)\n",
    "        joined_image.save(target + file.split('.')[0] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(target)\n",
    "joined_image.save(target + file.split('.')[0] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
