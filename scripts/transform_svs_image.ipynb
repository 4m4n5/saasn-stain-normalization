{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openslide as opsl\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import utils\n",
    "from arch import define_Gen, define_Dis\n",
    "import kornia\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage.transform\n",
    "import argparse\n",
    "from scipy.misc import imread, imresize\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.feature_extraction.image import reconstruct_from_patches_2d as reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments(object):\n",
    "    def __init__(self, dictionary):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        for key in dictionary:\n",
    "            setattr(self, key, dictionary[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'epochs': 30,\n",
    "    'decay_epoch': 25,\n",
    "    'batch_size': 16,\n",
    "    'lr': 0.0002,\n",
    "    'load_height': 128,\n",
    "    'load_width': 128,\n",
    "    'gpu_ids': '0',\n",
    "    'crop_height': 128,\n",
    "    'crop_width': 128,\n",
    "    'alpha': 5, # Cyc loss\n",
    "    'beta': 5, # Scyc loss\n",
    "    'gamma': 2, # Dssim loss \n",
    "    'delta': 0.1, # Identity\n",
    "    'training': True,\n",
    "    'testing': True,\n",
    "    'results_dir': '/project/DSone/as3ek/data/ganstain/500/results/',\n",
    "    'dataset_dir': '/project/DSone/as3ek/data/ganstain/500/',\n",
    "    'checkpoint_dir': '/project/DSone/as3ek/data/ganstain/500/checkpoint/',\n",
    "    'norm': 'batch',\n",
    "    'use_dropout': False,\n",
    "    'ngf': 64,\n",
    "    'ndf': 64,\n",
    "    'gen_net': 'unet_128',\n",
    "    'dis_net': 'n_layers',\n",
    "    'self_attn': True,\n",
    "    'spectral': True,\n",
    "    'log_freq': 50,\n",
    "    'custom_tag': 'p100',\n",
    "    'gen_samples': True,\n",
    "    'specific_samples': False\n",
    "}\n",
    "\n",
    "args = Arguments(args)\n",
    "\n",
    "tag1 = 'noattn'\n",
    "if args.self_attn:\n",
    "    tag1 = 'attn'\n",
    "\n",
    "tag2 = 'nospec'\n",
    "if args.spectral:\n",
    "    tag2 = 'spectral'\n",
    "\n",
    "# Generate paths for checkpoint and results\n",
    "args.identifier = str(args.gen_net) + '_' + str(args.dis_net) + '_' \\\n",
    "+ str(args.lr) + '_' + args.norm + '_' + tag1 + '_' + tag2 + '_' + str(args.batch_size) + '_' \\\n",
    "+ str(args.load_height) + '_coefs_' + str(args.alpha) + '_' + str(args.beta) + '_' + str(args.gamma) + '_'\\\n",
    "+ str(args.delta) + '_' + args.custom_tag\n",
    "\n",
    "args.checkpoint_path = args.checkpoint_dir + args.identifier\n",
    "args.results_path = args.results_dir + args.identifier\n",
    "\n",
    "args.gpu_ids = []\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    args.gpu_ids.append(i)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network initialized with weights sampled from N(0,[0.02]).\n",
      "Network initialized with weights sampled from N(0,[0.02]).\n"
     ]
    }
   ],
   "source": [
    "Gab = define_Gen(input_nc=3, output_nc=3, ngf=args.ngf, netG=args.gen_net, norm=args.norm, \n",
    "                                                    use_dropout= args.use_dropout, gpu_ids=args.gpu_ids, self_attn=args.self_attn, spectral = args.spectral)\n",
    "Gba = define_Gen(input_nc=3, output_nc=3, ngf=args.ngf, netG=args.gen_net, norm=args.norm, \n",
    "                                                    use_dropout= args.use_dropout, gpu_ids=args.gpu_ids, self_attn=args.self_attn, spectral = args.spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Loading checkpoint from /project/DSone/as3ek/data/ganstain/500/checkpoint/unet_128_n_layers_0.0002_batch_attn_spectral_16_128_coefs_5_5_2_0.1_p100/latest.ckpt succeed!\n"
     ]
    }
   ],
   "source": [
    "ckpt = utils.load_checkpoint('%s/latest.ckpt' % (args.checkpoint_path))\n",
    "Gab.load_state_dict(ckpt['Gab'])\n",
    "Gba.load_state_dict(ckpt['Gba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval mode\n"
     ]
    }
   ],
   "source": [
    "Gab.eval()\n",
    "Gba.eval()\n",
    "print('Eval mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "to_pink = True\n",
    "PATH = '/project/DSone/biopsy_images/chrc_data_case_preserved/train/EE/'\n",
    "size = 256\n",
    "target = '/scratch/as3ek/normalized_svs/'\n",
    "target_path = '/scratch/as3ek/normalized_svs/patches/'\n",
    "for file in os.listdir(PATH):\n",
    "    if file == '130370_6722_001.svs':\n",
    "        continue\n",
    "    image = opsl.OpenSlide(PATH + file)\n",
    "    new_dims = (image.dimensions[0] // 256) * 256 , (image.dimensions[1] // 256) * 256 \n",
    "    joined_image = Image.new('RGB', (new_dims))\n",
    "    for vert_count in range(image.dimensions[1] // size):\n",
    "        y_cord = size * vert_count\n",
    "        for hor_count in range(image.dimensions[0] // size):\n",
    "            x_cord = size * hor_count\n",
    "            patch = image.read_region((x_cord, y_cord), 0, (size, size))\n",
    "            patch = patch.convert('RGB')\n",
    "            patch = imresize(patch, (256, 256))\n",
    "            patch = patch.transpose(2, 0, 1)\n",
    "            patch = patch / 255.\n",
    "            patch = torch.FloatTensor(patch).to(device)\n",
    "            patch = transform(patch)\n",
    "            patch = patch.unsqueeze(0)\n",
    "            \n",
    "            if to_pink:\n",
    "                out = Gba(patch)\n",
    "            else:\n",
    "                out = Gab(patch)\n",
    "            target_folder = target_path + file.split('.')[0]\n",
    "            if not os.path.exists(target_folder):\n",
    "                os.mkdir(target_folder)\n",
    "            filename = target_folder + '/' + file.split('.')[0] + '_' + str(x_cord) + '_' + str(y_cord) + '.png'\n",
    "            \n",
    "            torchvision.utils.save_image((out + 1)/2, filename)\n",
    "            \n",
    "            out = (out + 1) / 2\n",
    "            # this converts it from GPU to CPU and selects first image\n",
    "            img = out.detach().cpu().numpy()[0]\n",
    "            #convert image back to Height,Width,Channels\n",
    "            img = np.transpose(img, (1,2,0))\n",
    "            patch_join = Image.fromarray(np.uint8(img*255))\n",
    "            \n",
    "            joined_image.paste(patch_join, (x_cord, y_cord))\n",
    "            \n",
    "    joined_image.save(target + '/' + file.split('.')[0] + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
